---
title: "Assignment 10: Regularization"
author: "Aaron Riedling"
date: "2025-01-07"
output: html_document
---

## Introduction

Zeller et al. (2014) studied metagenome sequencing data from fecal samples of 156 humans that included colorectal cancer patients and tumor-free controls.
Their aim was to see whether they could identify biomarkers (presence or abundance of certain taxa) that could help with early tumor detection.
The data are available from Bioconductor through its ExperimentHub service under the identifier EH361.

You can access the data with the following code:
```{r}
# load the csv file zeller_abundances.csv
zeller <- read.csv("zeller_abundances.csv", row.names = 1)

# Convert relative abundances to integer counts
scaling_factor <- 10000
zeller_counts <- data.frame(lapply(zeller, function(x) {
    as.integer(round(x * scaling_factor))
}))
# Keep the same row names if they exist
row.names(zeller_counts) <- row.names(zeller)

# Remove the "UNMAPPED" row
zeller_counts <- zeller_counts[-which(rownames(zeller_counts) == "UNMAPPED"), ]

head(zeller_counts)
# Read the labels file
labels <- read.csv("labels.csv")

# Create cancer status vector
cancer_status <- data.frame(
    sample_id = colnames(zeller_counts),
    cancer = NA
)

# Convert dots back to dashes in sample_id for matching
cancer_status$sample_id_original <- cancer_status$sample_id
cancer_status$sample_id <- gsub("\\.", "-", cancer_status$sample_id)

# Set cancer status based on Diagnosis
for(i in 1:nrow(cancer_status)) {
    sample <- cancer_status$sample_id[i]
    if(sample %in% labels$Sample.ID) {
        diagnosis <- labels$Diagnosis[labels$Sample.ID == sample]
        cancer_status$cancer[i] <- ifelse(diagnosis == "Normal", 0, 1)
    }
}

# Remove the temporary matching column
cancer_status$sample_id <- cancer_status$sample_id_original
cancer_status$sample_id_original <- NULL

# Verify results
head(cancer_status)
table(cancer_status$cancer, useNA="ifany")  # shows distribution including any NA values

# Check that we found matches
sum(!is.na(cancer_status$cancer))  # number of matched samples


```


## Task 1: Data Loading and Preparation (15 pts)
Load the Zeller data, create a test and training set using a 70/30 split. Make sure to maintain the class balance in the split.

```{r task1_test}
# Your solution here!


library(caret)  # For the createDataPartition function

# Load Zeller data
zeller <- read.csv("zeller_abundances.csv", row.names = 1)

# Convert relative abundances to integer counts
scaling_factor <- 10000
zeller_counts <- data.frame(lapply(zeller, function(x) {
  as.integer(round(x * scaling_factor))
}))
# Keep the same row names if they exist
row.names(zeller_counts) <- row.names(zeller)

# Remove the "UNMAPPED" row
zeller_counts <- zeller_counts[-which(rownames(zeller_counts) == "UNMAPPED"), ]

# Read the labels file
labels <- read.csv("labels.csv")

# Create cancer status vector
cancer_status <- data.frame(
  sample_id = colnames(zeller_counts),
  cancer = NA
)

# Convert dots back to dashes in sample_id for matching
cancer_status$sample_id_original <- cancer_status$sample_id
cancer_status$sample_id <- gsub("\\.", "-", cancer_status$sample_id)

# Set cancer status based on Diagnosis
for (i in 1:nrow(cancer_status)) {
  sample <- cancer_status$sample_id[i]
  if (sample %in% labels$Sample.ID) {
    diagnosis <- labels$Diagnosis[labels$Sample.ID == sample]
    cancer_status$cancer[i] <- ifelse(diagnosis == "Normal", 0, 1)
  }
}

# Remove the temporary matching column
cancer_status$sample_id <- cancer_status$sample_id_original
cancer_status$sample_id_original <- NULL

# Combine zeller_counts and cancer_status into one data frame
zeller_data <- t(zeller_counts)  # Transpose so rows are samples
zeller_data <- as.data.frame(zeller_data)
zeller_data$cancer <- cancer_status$cancer

# Check for any NA cancer statuses
if (any(is.na(zeller_data$cancer))) {
  stop("Some samples have missing cancer status.")
}

# Split data into training and testing sets (70/30) while maintaining class balance
set.seed(123)  # For reproducibility
train_index <- createDataPartition(zeller_data$cancer, p = 0.7, list = FALSE)
train_set <- zeller_data[train_index, ]
test_set <- zeller_data[-train_index, ]

# Check the class distribution in train and test sets
cat("Class distribution in training set:\n")
print(table(train_set$cancer))

cat("\nClass distribution in testing set:\n")
print(table(test_set$cancer))




```

## Task 2: Why Regularization (25 pts)
As discussed in the lecture, regularization is a method to control the variance-bias tradeoff. This problem is also often paraphrased as controlling overfitting.

Regularization is needed in the first place because high dimensional spaces (such as the feature space of the Zeller data) are so huge that these spaces are mostly empty (curse of dimensionality).

To get a feeling for this effect, calculate the sparsity (here defined as the sample count/volume) of the Zeller data set:

1. To calculate the volume for the first 50 dimensions, calculate the length/ range of each dimension using the respective min and max value in the data.
2. Calculate the volume of the space spanned by the data using the calculated lengths for each dimension.
3. Use the volume to calculate the sparsity as the number of samples divided by the volume of the space
4. Plot a graph showing the sparsity of the Zeller data set for increasing number of dimensions (one to 50)
   - X-axis: number of dimensions
   - Y-axis: sparsity

What do you see?
```{r task2_test}
# Your solution here!

library(ggplot2)

# Extract the first 50 dimensions
zeller_data_subset <- zeller_data[, 1:50]

# Calculate the range (max - min) for each dimension
dimension_ranges <- apply(zeller_data_subset, 2, function(x) {
  max(x) - min(x)
})

# Check for zero ranges and handle them by replacing with a small value (e.g., 1e-6)
dimension_ranges[dimension_ranges == 0] <- 1e-6

# Calculate the volume of the space spanned by the data (product of ranges)
volumes <- sapply(1:50, function(d) {
  prod(dimension_ranges[1:d])
})

# Calculate sparsity (number of samples / volume)
sparsity <- nrow(zeller_data) / volumes

# Check the range of sparsity values
cat("Sparsity values:\n")
print(sparsity)

# Create a data frame for plotting
sparsity_df <- data.frame(
  dimensions = 1:50,
  sparsity = sparsity
)

# Plot sparsity with log scale for Y-axis
ggplot(sparsity_df, aes(x = dimensions, y = sparsity)) +
  geom_point(size = 3, color = "blue") + # Increase point size for visibility
  scale_y_log10() +  # Use log scale for the Y-axis
  labs(title = "Sparsity of the Zeller Dataset",
       x = "Number of Dimensions",
       y = "Sparsity (Samples / Volume)") +
  theme_minimal()







```

## Task 3: Regularization Techniques (35 pts)
To tackle regularization, several techniques have been developed.

In this task, you will explore three of them: `Ridge`, `Lasso` and `Elastic Net` regularization.

1. Fit an unregularized linear model and three models using the three regularization techniques to the training split
2. Use the `glmnet` package and the `glm()` function to fit the models
3. You can choose the regularization using the `alpha` parameter
4. Use the `cv.glmnet()` function to perform cross-validation and find the optimal lambda parameter for the three regularized models

```{r task3_test}
# Your solution here!
# Load necessary libraries
library(glmnet)
library(caret)

# Prepare the training data (features only, excluding the target variable 'cancer')
train_features <- train_set[, -ncol(train_set)]  # Exclude the 'cancer' column
train_target <- train_set$cancer

# Fit an unregularized linear model using glm()
unreg_model <- glm(cancer ~ ., data = train_set, family = binomial)

# Fit a Ridge Regression model (alpha = 0)
ridge_model <- cv.glmnet(as.matrix(train_features), train_target, alpha = 0, family = "binomial")

# Fit a Lasso Regression model (alpha = 1)
lasso_model <- cv.glmnet(as.matrix(train_features), train_target, alpha = 1, family = "binomial")

# Fit an Elastic Net model (alpha = 0.5, mix of Ridge and Lasso)
elastic_net_model <- cv.glmnet(as.matrix(train_features), train_target, alpha = 0.5, family = "binomial")

# Print the best lambda values from cross-validation for each model
cat("Best lambda for Ridge Regression: ", ridge_model$lambda.min, "\n")
cat("Best lambda for Lasso Regression: ", lasso_model$lambda.min, "\n")
cat("Best lambda for Elastic Net Regression: ", elastic_net_model$lambda.min, "\n")

# Plot the cross-validation results for each model
par(mfrow = c(1, 3))  # Arrange plots side by side
plot(ridge_model)
plot(lasso_model)
plot(elastic_net_model)


```

## Task 4: Model Evaluation (25 pts)
Evaluate the performance of the models on the test split using the accuracy against lambda values.
Compare the results with the unregularized model.
```{r task4_test}
# Your solution here!
# Prepare the test data (features only, excluding the target variable 'cancer')
test_features <- test_set[, -ncol(test_set)]  # Exclude the 'cancer' column
test_target <- test_set$cancer

# Predict with the unregularized linear model (logistic regression)
unreg_preds <- predict(unreg_model, newdata = test_set, type = "response")
unreg_preds_binary <- ifelse(unreg_preds > 0.5, 1, 0)  # Convert probabilities to binary outcomes
unreg_accuracy <- mean(unreg_preds_binary == test_target)

# Predict with the Ridge Regression model (use the best lambda)
ridge_preds <- predict(ridge_model, newx = as.matrix(test_features), s = "lambda.min", type = "response")
ridge_preds_binary <- ifelse(ridge_preds > 0.5, 1, 0)
ridge_accuracy <- mean(ridge_preds_binary == test_target)

# Predict with the Lasso Regression model (use the best lambda)
lasso_preds <- predict(lasso_model, newx = as.matrix(test_features), s = "lambda.min", type = "response")
lasso_preds_binary <- ifelse(lasso_preds > 0.5, 1, 0)
lasso_accuracy <- mean(lasso_preds_binary == test_target)

# Predict with the Elastic Net model (use the best lambda)
elastic_net_preds <- predict(elastic_net_model, newx = as.matrix(test_features), s = "lambda.min", type = "response")
elastic_net_preds_binary <- ifelse(elastic_net_preds > 0.5, 1, 0)
elastic_net_accuracy <- mean(elastic_net_preds_binary == test_target)

# Print accuracies for comparison
cat("Accuracy of Unregularized Model: ", unreg_accuracy, "\n")
cat("Accuracy of Ridge Regression: ", ridge_accuracy, "\n")
cat("Accuracy of Lasso Regression: ", lasso_accuracy, "\n")
cat("Accuracy of Elastic Net Regression: ", elastic_net_accuracy, "\n")

# Create a data frame to compare accuracies
accuracy_df <- data.frame(
  Model = c("Unregularized", "Ridge", "Lasso", "Elastic Net"),
  Accuracy = c(unreg_accuracy, ridge_accuracy, lasso_accuracy, elastic_net_accuracy)
)

# Plot the accuracies
library(ggplot2)
ggplot(accuracy_df, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity", color = "black", show.legend = FALSE) +
  geom_text(aes(label = round(Accuracy, 3)), vjust = -0.5) +
  labs(title = "Model Comparison: Accuracy on Test Set",
       x = "Model",
       y = "Accuracy") +
  theme_minimal()


```
